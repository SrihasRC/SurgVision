{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "685fb6f9",
   "metadata": {},
   "source": [
    "# YOLOv11 Segmentation Training on Kaggle P100 GPU\n",
    "## Surgical Organ Detection & Segmentation\n",
    "\n",
    "This notebook trains a YOLOv11n-seg model on Kaggle's P100 GPU (16GB VRAM) for detecting and segmenting anatomical structures during surgical operations.\n",
    "\n",
    "**Dataset Classes:**\n",
    "- External Iliac Artery\n",
    "- External Iliac Vein\n",
    "- Obturator Nerve\n",
    "- Ovary\n",
    "- Ureter\n",
    "- Uterine Artery\n",
    "- Uterus\n",
    "\n",
    "**Training Configuration:**\n",
    "- Model: YOLOv11n-seg (nano)\n",
    "- Batch Size: 16 (optimized for P100)\n",
    "- Image Size: 640x640\n",
    "- Epochs: 150\n",
    "- Expected Training Time: ~2-3 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f1d40",
   "metadata": {},
   "source": [
    "## 1. Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141a72b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU detected! Make sure GPU accelerator is enabled in Kaggle settings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a9c9d2",
   "metadata": {},
   "source": [
    "## 2. Install Ultralytics YOLOv11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900e26f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q ultralytics\n",
    "print(\"‚úÖ Ultralytics installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7cc23e",
   "metadata": {},
   "source": [
    "## 3. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757adcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Configure memory allocation\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e07e91",
   "metadata": {},
   "source": [
    "## 4. Upload and Verify Dataset\n",
    "\n",
    "**Instructions for Kaggle:**\n",
    "1. Upload your `medhack_yolov11` dataset as a Kaggle Dataset\n",
    "2. Add it to this notebook in \"Input\" section\n",
    "3. The dataset should be available at `/kaggle/input/your-dataset-name/`\n",
    "\n",
    "Or, modify the path below to match your dataset location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e070198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Kaggle input directory\n",
    "print(\"Available datasets in /kaggle/input:\")\n",
    "if os.path.exists('/kaggle/input'):\n",
    "    for item in os.listdir('/kaggle/input'):\n",
    "        print(f\"  - {item}\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è Not running on Kaggle - using local path\")\n",
    "\n",
    "# Set dataset path - MODIFY THIS to match your dataset location\n",
    "DATASET_PATH = '/kaggle/input/medhack-yolov11'  # Change to your dataset name\n",
    "DATA_YAML = f'{DATASET_PATH}/data.yaml'\n",
    "\n",
    "# Verify dataset structure\n",
    "if os.path.exists(DATASET_PATH):\n",
    "    print(f\"\\n‚úÖ Dataset found at: {DATASET_PATH}\")\n",
    "    print(\"\\nDataset structure:\")\n",
    "    for root, dirs, files in os.walk(DATASET_PATH):\n",
    "        level = root.replace(DATASET_PATH, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f'{indent}{os.path.basename(root)}/')\n",
    "        if level < 2:  # Only show 2 levels deep\n",
    "            sub_indent = ' ' * 2 * (level + 1)\n",
    "            for file in files[:3]:  # Show first 3 files\n",
    "                print(f'{sub_indent}{file}')\n",
    "            if len(files) > 3:\n",
    "                print(f'{sub_indent}... and {len(files)-3} more files')\n",
    "else:\n",
    "    print(f\"\\n‚ùå Dataset not found at: {DATASET_PATH}\")\n",
    "    print(\"Please update DATASET_PATH variable to match your dataset location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d6fe55",
   "metadata": {},
   "source": [
    "## 5. Load YOLOv11n-seg Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebad630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained YOLOv11n-seg model\n",
    "print(\"Loading YOLOv11n-seg model with pretrained weights...\")\n",
    "model = YOLO('yolo11n-seg.pt')\n",
    "print(\"‚úÖ Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee56b9bb",
   "metadata": {},
   "source": [
    "## 6. Configure Training Parameters (P100 Optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d403978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration optimized for P100 (16GB VRAM)\n",
    "training_config = {\n",
    "    # Dataset\n",
    "    'data': DATA_YAML,\n",
    "    \n",
    "    # Training parameters\n",
    "    'epochs': 150,\n",
    "    'batch': 16,  # P100 can handle larger batches\n",
    "    'imgsz': 640,\n",
    "    'device': 0,  # GPU\n",
    "    'project': '/kaggle/working/runs/segment',\n",
    "    'name': 'surgical_organs_p100',\n",
    "    'exist_ok': True,\n",
    "    'verbose': False,\n",
    "    \n",
    "    # Optimization\n",
    "    'optimizer': 'AdamW',\n",
    "    'lr0': 0.001,\n",
    "    'lrf': 0.01,\n",
    "    'momentum': 0.937,\n",
    "    'weight_decay': 0.0005,\n",
    "    'warmup_epochs': 3.0,\n",
    "    'cos_lr': True,\n",
    "    \n",
    "    # Performance\n",
    "    'amp': True,  # Mixed precision\n",
    "    'workers': 8,\n",
    "    'cache': False,\n",
    "    'multi_scale': True,\n",
    "    \n",
    "    # Medical-specific augmentation (conservative)\n",
    "    'hsv_h': 0.010,\n",
    "    'hsv_s': 0.5,\n",
    "    'hsv_v': 0.3,\n",
    "    'degrees': 5.0,\n",
    "    'translate': 0.1,\n",
    "    'scale': 0.3,\n",
    "    'shear': 0.0,\n",
    "    'perspective': 0.0,\n",
    "    'flipud': 0.0,\n",
    "    'fliplr': 0.5,\n",
    "    'mosaic': 0.8,\n",
    "    'mixup': 0.1,\n",
    "    'copy_paste': 0.2,\n",
    "    'auto_augment': 'randaugment',\n",
    "    'erasing': 0.2,\n",
    "    \n",
    "    # Validation & Saving\n",
    "    'val': True,\n",
    "    'save': True,\n",
    "    'save_period': 10,\n",
    "    'patience': 30,\n",
    "    'plots': True,\n",
    "    \n",
    "    # Segmentation\n",
    "    'overlap_mask': True,\n",
    "    'mask_ratio': 4,\n",
    "    \n",
    "    # Loss weights\n",
    "    'box': 7.5,\n",
    "    'cls': 0.5,\n",
    "    'dfl': 1.5,\n",
    "    \n",
    "    # Other\n",
    "    'close_mosaic': 10,\n",
    "    'seed': 42,\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  Model: YOLOv11n-seg\")\n",
    "print(f\"  Epochs: {training_config['epochs']}\")\n",
    "print(f\"  Batch Size: {training_config['batch']}\")\n",
    "print(f\"  Image Size: {training_config['imgsz']}\")\n",
    "print(f\"  Device: GPU (P100)\")\n",
    "print(f\"  Expected Time: 2-3 hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7aaa0e",
   "metadata": {},
   "source": [
    "## 7. Train Model\n",
    "\n",
    "This will take approximately 2-3 hours on P100 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9990ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"=\"*60)\n",
    "print(\"Starting Training...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = model.train(**training_config)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Training Complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f733adc9",
   "metadata": {},
   "source": [
    "## 8. Validate Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac68a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and validate\n",
    "best_model_path = '/kaggle/working/runs/segment/surgical_organs_p100/weights/best.pt'\n",
    "best_model = YOLO(best_model_path)\n",
    "\n",
    "print(\"Validating best model...\")\n",
    "metrics = best_model.val()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Validation Metrics:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Box Detection:\")\n",
    "print(f\"  mAP50:     {metrics.box.map50:.4f}\")\n",
    "print(f\"  mAP50-95:  {metrics.box.map:.4f}\")\n",
    "print(f\"  Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"  Recall:    {metrics.box.mr:.4f}\")\n",
    "print(f\"\\nSegmentation:\")\n",
    "print(f\"  mAP50:     {metrics.seg.map50:.4f}\")\n",
    "print(f\"  mAP50-95:  {metrics.seg.map:.4f}\")\n",
    "print(f\"  Precision: {metrics.seg.mp:.4f}\")\n",
    "print(f\"  Recall:    {metrics.seg.mr:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc272df2",
   "metadata": {},
   "source": [
    "## 9. Display Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e23503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Display training results plot\n",
    "results_path = '/kaggle/working/runs/segment/surgical_organs_p100/results.png'\n",
    "if os.path.exists(results_path):\n",
    "    print(\"Training Curves:\")\n",
    "    display(Image(filename=results_path))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Results plot not found\")\n",
    "\n",
    "# Display confusion matrix\n",
    "confusion_path = '/kaggle/working/runs/segment/surgical_organs_p100/confusion_matrix.png'\n",
    "if os.path.exists(confusion_path):\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    display(Image(filename=confusion_path))\n",
    "\n",
    "# Display validation batch predictions\n",
    "val_batch_path = '/kaggle/working/runs/segment/surgical_organs_p100/val_batch0_pred.jpg'\n",
    "if os.path.exists(val_batch_path):\n",
    "    print(\"\\nValidation Predictions:\")\n",
    "    display(Image(filename=val_batch_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39ff0d4",
   "metadata": {},
   "source": [
    "## 10. Save Model Weights\n",
    "\n",
    "The trained weights are automatically saved and can be downloaded from Kaggle's output section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c39c90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List saved model files\n",
    "weights_dir = '/kaggle/working/runs/segment/surgical_organs_p100/weights'\n",
    "print(\"Saved Model Weights:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if os.path.exists(weights_dir):\n",
    "    for file in os.listdir(weights_dir):\n",
    "        file_path = os.path.join(weights_dir, file)\n",
    "        size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "        print(f\"  {file:20s} - {size_mb:.2f} MB\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Download these files from Kaggle Output:\")\n",
    "    print(f\"   best.pt  - Best model based on validation metrics\")\n",
    "    print(f\"   last.pt  - Final epoch checkpoint\")\n",
    "else:\n",
    "    print(\"‚ùå Weights directory not found\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüì• To download: Click 'Output' tab ‚Üí Download files\")\n",
    "print(\"   Or use Kaggle API to download programmatically\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0925e357",
   "metadata": {},
   "source": [
    "## 11. Export Model to ONNX (Optional)\n",
    "\n",
    "Export to ONNX format for faster CPU inference in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611deb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to ONNX format\n",
    "print(\"Exporting model to ONNX format...\")\n",
    "try:\n",
    "    onnx_path = best_model.export(format='onnx', imgsz=640)\n",
    "    print(f\"‚úÖ ONNX model exported successfully!\")\n",
    "    print(f\"   Location: {onnx_path}\")\n",
    "    print(f\"   This format provides 20-30% faster CPU inference\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Export failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3275dd26",
   "metadata": {},
   "source": [
    "## 12. Test Inference on Sample Image (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc32b2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference on a sample test image\n",
    "test_image_dir = f'{DATASET_PATH}/test/images'\n",
    "\n",
    "if os.path.exists(test_image_dir):\n",
    "    # Get first test image\n",
    "    test_images = [f for f in os.listdir(test_image_dir) if f.endswith(('.jpg', '.png'))]\n",
    "    if test_images:\n",
    "        test_img_path = os.path.join(test_image_dir, test_images[0])\n",
    "        \n",
    "        print(f\"Running inference on: {test_images[0]}\")\n",
    "        results = best_model.predict(test_img_path, conf=0.25, save=True, project='/kaggle/working')\n",
    "        \n",
    "        # Display result\n",
    "        result_path = '/kaggle/working/predict/image0.jpg'\n",
    "        if os.path.exists(result_path):\n",
    "            print(\"\\nInference Result:\")\n",
    "            display(Image(filename=result_path))\n",
    "        \n",
    "        print(f\"\\n‚úÖ Detected {len(results[0].boxes)} objects\")\n",
    "    else:\n",
    "        print(\"No test images found\")\n",
    "else:\n",
    "    print(f\"Test directory not found: {test_image_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846057bb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "‚úÖ **Training Complete!**\n",
    "\n",
    "**Model Files Available in Output:**\n",
    "- `best.pt` - Best model weights (download this!)\n",
    "- `last.pt` - Last epoch checkpoint\n",
    "- `best.onnx` - ONNX format (if exported)\n",
    "\n",
    "**Next Steps:**\n",
    "1. Download `best.pt` from Kaggle Output\n",
    "2. Use the model locally:\n",
    "   ```python\n",
    "   from ultralytics import YOLO\n",
    "   model = YOLO('best.pt')\n",
    "   results = model.predict('image.jpg')\n",
    "   ```\n",
    "\n",
    "**Expected Performance:**\n",
    "- Training Time: ~2-3 hours on P100\n",
    "- mAP50 (Seg): 0.65-0.80\n",
    "- Inference Speed: 15-25 FPS on GPU, 3-5 FPS on CPU\n",
    "\n",
    "**Hardware Used:**\n",
    "- GPU: NVIDIA P100 (16GB)\n",
    "- Batch Size: 16\n",
    "- Optimized for medical organ segmentation"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
